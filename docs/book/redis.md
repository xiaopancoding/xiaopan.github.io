# redis

#### redis通用命令

- **KEYS: 查看符合模板的的所有的key**，   但是不建议在生产环境中使用， 因为这样可能会导致系统阻塞

- **DEL: 删除一个指定的键**

- **exists：  判断一个键是否存在， 如果存在的话， 就返回  （integer） 1**

- **expire :  设置一个键的存活时间， 单位  秒**

- **TTL:  查看一个键的存活时间，**  如果是  -2，  就表示  已经不存在了， 如果是-1那么就表示  永久存在， 如果还在倒计时， 那么就是只剩下倒计时的时间

#### String类型的常见命令

- **set**  kye value:  如果该键， 没有就是添加，  如果有的话， 就是修改该键的值
  - [选项]
    - ex  ：   表示添加或修改这个键， 并添加这个键的存活时间
    - px：     以毫秒为单位设置过期时间
    - exat：    设置以秒为单位的  UNIX时间戳所对应的时间为过期时间
    - nx：    判断这个键， 是否存在，  如果存在，就不执行这个 命令， 如果不存在就执行
    - get:      表示获取  这个键  之前的值，  如果是  这个键  之前没有值的话， 那么就是  nil，  如果有的话， 就是  获取原来的值，然后再进行设置
    - keepttl：    保留设置前指定键的生存时间，  如果不设置这个的话， 之前设置了生存时间， 修改的话， 就会完全覆盖，变成永久存活，  如果设置了  这个选项的话， 那么就会保留剩余的时间
- **get ** key :  获取指定键的值
- getrange key  start end  :    表示获取  这个键的值的  指定长度，    其实就是 截取一段长度， 下标从零开始
- setrange key start end:     表示把指定位置上， 值进行覆盖，下标也是从零开始
- **mset** key value [key value...] ：  批量添加String类型的键值对
- **mget** key [key ...]:  根据多个key获取多个String类型的value
- getset key value:    先get然后再set
- incr:    让整型的key的值  自增  一
- incrby： 让一个整型的key的值自增，  并且要指定步长
- decr:   让整型的key的值，  自减1
- decrby:   让一个整型的key的值减少， 要指定步长
- incrbyfloat：  一个浮点型的key的值， 自增，  也是要指定步长的
- setnx:   添加一个String类型的键值对，  前提是这个key是不存在的， 如果存在， 那么就不执行
- setex:  添加一个String类型的键值对， 并且是指定这个键的存活时间

在redis中 如果要出现  层级分明的话  那么就要  使用  ```:```分割，  比如  user: 1    '{"name": "pan", "age": "10"}',  这里表示的就是一个层级的关系，  就是用户 id为1的  人的  信息，  里面有  姓名， 年龄等

#### Hash类型的常见命令

- hset :    添加或则修改  hash类型key的field的键的值，  field是里面hash的键
- hget： 通过指定的，  key，  再通过  指定的  field的键， 获取  hash类型里面的值
- hmset:   在key中 批量添加hash类型的  键值对，   但是redis的键 也就是  key一个
- hmget：   在key中  批量获取  hash类型中  指定 field键的  值，  可以写多个 field键
- hgetall :  通过指定的  key， 获取全部  field的键
- hkeys key:   获取这个键里面  所有的哈希类型的键
- hvals key:  获取这个键里面  所有的哈希类型的值
- hincrby ：  通过指定  key，  然后在指定一个  field键， 使这个键对应的值  增加一个  步长
- hsetnx:   添加一个hash类型的key的field键， 前提是这个field不存在， 否则不执行
- hlen key:   获取这个键里面有多少个 哈希类型的个数
- hdel key field：  删除key键的field这个键的值 ，  是删除哈希数据

#### List类型的常见命令

list底层使用的 双向链表

- lpush key element [element ...]:   向列表的左侧一个键值对， 或多个,  也就是说  element是可以多个的，但是key是不能多个的
- rpush key element [element ...]:   向列表右侧插入一个或多个元素，也是element可以多个， 但是key也就是一个， 这个key可以lpush的key相同
- lpop  key [count]： 如果count不写的话， 那么默认就是  移除并返回左侧第一个元素， 如果没有则返回  nil， 如果写的 话， 就是移除并返回  左侧 几个元素，  这个几个元素就取决于  count填了几了
- rpop key [count]:      如果count不写的话， 那么默认就是  移除并返回右侧第一个元素， 如果没有则返回  nil， 如果写的 话， 就是移除并返回  右侧 几个元素，  这个几个元素就取决于  count填了几了
- lrange  key  star end:   返回一段角标范围内的所有元素， 它这个角标是从零开始，
- lrem key n value:     表示删除键key中  n个value的值，   当然如果没有n个， 就是删除少于n个也是可以的
- lset key index value:   表示  把index位置上的值， 设置为  value 
- rpoplpush key1 key2:    表示从key1中弹出一个值， 然后再插入key2的列表中
- llen key:    表示获取这个键里面有多少个  元素
- lindex key index:    表示获取  这个键里面的  索引为 index的值
- blpop和brpop:   与上面的 lpop 和rpop  相似， 只不过 如果没有元素可以删除的话 ，那么就会进入阻塞状态
- linsert key before/after :   表示在已有位置上 的前后插入一个值

#### Set类型的常见命令

- sadd key member [member]  :   向set中添加一个或多个元素
- srem key member [member] :   移除set中指定元素
- scard key:   返回set中元素的个数
- sismember key member:   判断一个元素是否存在于set中，  如果在的话， 就返回一个  影响的个数， 不在就返回0
- smembers:  获取set中的所有元素
- sinter key1 key2:   求key1 和 key2 的交集
- sdiff key1 key2 : 求key1 和key2 的差集
- sunion key1 key2:  求key1 和key2 的并集
- smove key1 key2 value:   把key1中value移动到  key2中来
- srandmember key n：   在key这集合中 随机 显示 这个  n  数字， 但不会删除集合中任何值
- spop key n:   在key这个集合中  随机显示  n数字， 但是这n个数字就被删除了
- sintercard number key1 key2 limit n :  number表示几个集合， 比如这里是两个集合， 那么就是返回这两个集合交集元素的个数， limit 表示限定几个

#### SortedSet类型的常见命令

这种类型主要针对于  成绩的，  或则排行榜，  一个名字， 一个分数， 

- zadd key score member:  添加一个或多个元素到  sort set ,如果 已经存在则更新其score值，  这样是先写  数字， 然后再写名字
- zrem key member:  删除sort set中的一个指定元素
- zscore key  member: 获取  sort set中的指定元素的  score值
- zrank key member：  获取  sort set中指定元素的排名
- zcard key，  获取sorted set中元素的个数
- zcount key min max :  统计score值在给定范围内的所有元素的个数
- zincrby key increment member :  让sorted set中的指定元素自增， 步长为指定的increment值
- zrange key min max:   按照score排序后， 获取指定排名内元素
- zrangebyscore key min max:  按照score排序， 获取指定score范围内的元素
- zdiff,  zinter, zunion:   求  差集，  交集，  并集
- zmpop number1 key min count 1:     number表示弹出几个， 在哪个key中，  min表示最小的，  count数量， 1个

#### BitMap(位图)类型的常见命令

用String类型作为底层的数据结构实现的一种统计二值状态的数据类型， 是基于String数据类型的按位的操作， 只能由0和1，

其实一般用来计数， 就是在签到里  看你一个月来了几次，或则说一年之内来了几次， 0表示就是没来， 1 表示来了

- setbit key offset val:     给指定的 key的值 的第offset位，  赋上一个  val值
- getbit key offset:  获取指定key的第offset位的  值
- bitcount key start end：    返回指定key中 [start, end] 中为1的数量，如果是签到里面的话， 那么就是表示你来了几天
- bitop operat ion destkey key[key ...]  ：   operation表示进行的方式，  位运算有四种， and(按位与)， or(按位或)， not(非)， xor(异或)，destkey表示最后新得得数据存放的键， 而key, 则表示  这两个键的里面的  0和1的值进行 按位运算
- strlen  key：    返回这个键里的数据 占用多少个  字节，  一个字节等于八个bit，   在bitmap类型中， 每八个位为一组， 也就是说，如果到了八个位， 那么就会再自动申请八个位 

#### Hperloglog(基数统计)类型的常见命令

只是根据输入元素来计算基数，而不会存储输入的数据本身， 而且这里的基数是经过去重了的，  基数是一种数据集， 去重后的真实个数，基数统计 是用于统计一个集合中不重复的元素个数，就是对集合去重复剩余元素的计算，  一般用来做网站的UV统计， 如果一个人重复登录， 如果IP是一个的话， 那么就只记录一次，     它这个是 ``牺牲精确率来换取空间，  误差仅仅只是0.81%左右``

- pfadd key elememt [elememt ...] ：  往key中添加数据， 这个数据可以一次性添加多个，  也就是一个键对应 多个值
- pfcount key [key ...]:   返回给定HyperLogLog的基数估算值，  这个也只是估算的，
- pfmerge destkey sourcekey [sourcekey ...]:   将多个HyperLogLog合并为一个HyperLogLog

#### GEO(地理空间) 类型的常见命令

地球上的地理位置是使用二维的经纬度表示， 经度范围(-180, 180]， 纬度范围(-90,90]，也就是说 如果给了一个二维的经度和纬度，那么就能知道在地球的哪个位置

- geoadd key longitude latitude member [longitude latitude member ...]:   longitude经度， latitude维度， member该位置的名称，  也就是添加一个或多个 经度纬度名称  到key中
- redis-cli -h xxxx -a xxx --raw:    这样能解决 中文乱码问题
- 因为 GEO的类型是 zset的， 所以也能使用  
  - zrange key start end：     返回指定范围内的地理的名称
- geopos key member [member ...]:   返回指定key中， 名称的经纬度
- geohash key member [member ...]:   返回指定key中，名称的经纬度，但是这些经纬度经过哈希算法运算的
- geodist key membet1 member2 (m, km):   返回指定key中，  member1 和member2的距离， 有m，km等单位
- georadius key 精度 纬度 10km withdist withcoord count 10 withhash desc
  - 10km表示  在10km以内的
  - withdist：  相差的距离一并返回
  - withcoord：  查找的附近的xxx的  经纬度一并返回
  - count n：   表示返回几天数据
- georadiusbymember:   和上面的一样， 但是上面需要精确的  经纬度， 但是这个只需要， 一个名称就行了

#### Redis持久化

因为redis是内存数据库， 也就是说是存储在内存中的， 但是这样会 出现问题， 比如 服务器突然宕机， 停电什么的， 这样就会使数据丢失， 为了防止这样的事情放生的， 就要写一个备份， 这个备份就是  Redis的持久化。 redis的持久化有三种

1. RDB持久化
2. AOF持久化
3. RDB和AOF持久化相结合

##### RDB持久化

> RDB: RDB持久 是指 在以指定的时间间隔 执行数据集 的 时间点 快照（重点是 ```数据集```）



> - 这个快照文件 就称之为  RDB文件  默认是 (dump.rdb),  RDB是Redis DataBase的缩写
>
> - 一旦开启这个服务， 那么系统就会自动读取， 这个dump.rdb文件， 恢复之前数据
>
> 总的来说：  就是在指定的时间间隔内讲内存种的数据集 快照 写入磁盘种， 用行话讲就是  Snapshot内存快照， 它恢复时再讲快照文件直接都回到内存里

Redis的数据都在内存里中的， 保存备份时它执行的是全量快照， 也就是说， 把内存中的所有数据都记录到磁盘中

> 在Redis6以下，  是自动触发  在 ```redis.conf``` 配置文件中的SNAPSHOTtING下配置 save参数，来触发Redis的RDB持久化条件

```
save seconds changes
```

- save :  是保存的的意思，命令

- seconds:    表示在  seconds时间内，  单位是秒    
- changes：   表示改变了  这么多次命令

> save 900 1:     表示每隔 900s(15min),   如果有超过1个key发生了变化， 就写一份新的 RDB文件

总的来说：  就是  在seconds 秒内 改变了  changes次的数量， 那么就会 自动触发  bgsave

> 在Redis7中，  将持久化文件RDB的保存规则发生了改变，  尤其是  时间记录频度  发生了变化，  在时间间隔内发生的key的变化，  这个时间  变长了，  也就是  频率变低了

如果自己要尝试  使用RDB持久， 那么就要到redis.conf 配置文件中的  SNAPSHOTTING的位置上  添加  save m n

![image-20230316212435339](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230316212435339.png)

可以在这样的位置上填加  ```save m n``` ， 这样能覆盖  系统默认的值， 也就是说， 你想怎么写就怎么写了

> 之后可以修改 dump文件保存的路径

![image-20230316212537872](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230316212537872.png)

只要把  这个  ```dir ./```   给改掉， 也就是后面写一个你想放位置的路径， 但前提是这个路径是存在的

如果想要获取 配置文件中的信息的话， 那么可以使用命令

- config get xxx：  获取配置文件中的信息
  - config get dir  ：   这个就是获取 配置文件中的  dump.rdb文件的  路径

![image-20230316212933869](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230316212933869.png)

在这个位置上能修改，  dump.rdb文件的名称， 

必须是要在  它的时间间隔中改变了 >= changes次的key，  不然  dump.rdb文件不会有任何变化，  

**如果要恢复的话， 那么就将备份文件移动到  redis按照目录 并启动服务即可**

> **如果执行  flushall / flushdb命令 也会产生 dump.rdb文件，  但里面是空， 因为是先清空内存中所有的数据， 之后再执行备份的**
>
> **所以就一定是空的，   所以此时的dump.rdb文件没有任何意义**。     所以备份一定要 分隔备份， 备份文件和服务器不要在同一台物理机上

Save 和 bgsave 这两个命令能生成 RDB文件

> save :     在主程序中执行会阻塞当前 redis服务器， 直到持久化工作完成执行save命令， 这期间redis不能处理其他的命令， 在工作中是禁止使用， 因为一旦redis服务器进入阻塞状态， 就会有成百上千的命令不能执行，这是很严重的问题

> bgsave:  redis会在后台异步进行快照， 不会阻塞， 快照同时还可以响应客户端的请求， 该触发方式会fork一个子进程，有子进程复复制持久化过程，  这个子进程 就是和主进程异步进行的，由后天进行的

> fork:   在Linux程序中， fork() 会产生一个和父进程完全相同的子进程， 但是子进程在此后会exec系统调用，处于效率考虑，尽量避免膨胀

RDB优势： 

- 适合大规模的数据恢复
- 按照业务定时备份
- 对数据的完整性和一致性要求不高
- RDB文件在内存中的加载速度要比AOF快得多

RDB缺点

- 在一定间隔做一次备份， 这样的话 ， 会导致快照之间的数据的丢失， 主要是在那个时间间隔内做了一些key的改变但是还没有到量，就宕机了， 这时改变了那么些命令， 就没有保存进rdb文件
- 内存数据的全量同步， 如果数据量太大会导致I/O严重影响服务器性能
- RDB依赖于主进程的fork， 在更大的数据集中， 这可能会导致服务器请求的瞬间延迟。

如果一旦 数据丢失了的话， 那么就执行  redis-check-rdb  xxx/dump.rdb  如果能恢复就恢复，不能恢复就不能恢复了

##### AOF持久化

> 以日志的形式来记录每个写操作，  AOF持久化，**只记录写的操作，不会记录读取的操作**。 将Redis执行过的所有写指令记录下来， 只许追加文件但不可以改写文件， redis启动之初会读取该文件重新构建数据， 换而言之，redis重启的话就根据 日志文件的内容将写指令从前往后再执行一次，已完成数据的恢复工作

默认情况下，redis是没有开启AOF(apppend only file)的。  如果要开启AOF功能的话，就需要进入配置文件，

把  **appendonly on 改为  appendonly yes**，   AOF持久化保存的是  appendonly.aof文件， 而RDB持久化保存的是  dump.rdb文件

- AOF持久化工作流程：

![image-20230318154148760](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318154148760.png)



| 1    | Client作为命令的来源， 其实就是客户端的操作的命令， 会有多个源头以及源源不断的请求命令 |
| ---- | ------------------------------------------------------------ |
| 2    | 在这些命令到达 Redis Server以后并不是直接写入 AOF文件， 而是会将这些命令先放入AOF缓存中进行保存。**这里的AOF缓冲区实际上是内存中的一片区域**，存在的目的是当这些命令达到一定量以后再写入磁盘，避免频繁的磁盘IO操作。 |
| 3    | AOF缓冲会根据AOF缓存区**同步文件的三种写回策略**将命令写入磁盘上的AOF文件 |
| 4    | 随着写入AOF内容的增加为了避免文件膨胀，会根据规则进行命令的合并(又称 AOF重写)，从而起到AOF文件压缩的目的。 |
| 5    | 当Redis Server 服务器重启的时候会从AOF文件载入数据。         |

- AOF缓冲区三种写回策略：

  - Always：    同步写回， 每个写命令执行完立即同步地将日志写回磁盘
  - everysec:      每秒写回。 每个写命令执行完， 只是先把日志写到AOF文件的内存缓冲区， 然后每隔1秒把缓冲区中的内容写入磁盘
  - no:    操作系统控制的写回， 每个写命令执行完， 只是先把日志写到AOF文件的内存缓冲区， 然后由操作系统决定何时将这个缓冲区中内容写回磁盘中

  

| 配置项   | 写回时机             | 优点                        | 缺点                                      |
| -------- | -------------------- | --------------------------- | ----------------------------------------- |
| Always   | 同步写回             | 可靠性搞， 数据基本不会丢失 | 每个写命令都要同步写入磁盘， 性能影响较大 |
| Everysec | 每秒写回             | 性能适中                    | 宕机时会丢失1秒内的数据                   |
| No       | 由操作系统控制的写回 | 性能好                      | 宕机时丢失数据较多                        |

AOF的配置

默认是不开启的， 所以要去 redis.conf 配置文件中配置

![image-20230318161731545](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318161731545.png)

把该位置上的  no  改为  yes，就算是开启了 AOF持久化，  默认的写回策略是  everysec，也就是每隔一秒写回

![image-20230318162349393](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318162349393.png)

保存路径 在  Redis6中和Redis7中是不同的

- 在Redis6中
  - AOF保存文件的位置和RDB保存文件的位置是一样， 都是通过redis.conf配置文件的dir 配置
  - ![image-20230318162600654](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318162600654.png)

- 在Redis7中
  - ![image-20230318162911882](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318162911882.png)
  - 多了一层目录，  也就是  AOF文件也是单独放一个目录下
  - 但是， 这个目录是在  dir 配置目录下， 再加了一层
  - 例如：  dir /myredis            这里面放的是  RDB文件   **dir /myreids/dump.rdb**
  - 而AOF文件  在   **dir /myredis/appendonlydir/appendonly.aof**， 其实就是在存放RDB文件的目录中再建了一个单独的目录 存放 AOF文件

AOF文件的保存名称在redis6和redis7中也是不同的

- redis6中， 就是有且只有一个，  就是叫 appendonly.aof文件
- redis7中，  就改为了 Multi Part AOF的设计方式
  - base基本文件
  - incr增量文件
  - manifest清单文件

![image-20230318164044645](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318164044645.png)

MP - AOF实现：  就是将原来的单个AOF文件拆分成多个AOF文件。在MP - AOF中， 我们将AOF分为三种类型

- BASE：  表示基础AOF， 它一般有子进程通过重写产生，该文件只有一个
- INCR：  表示增量文件， 它一般会在AOFWR开始执行时被创建， 该文件可能存在多个
- HISTORY：  表示历史AOF， 它由BASE和INCR AOF变化而来， 每次AOFRW成功完成时， 本次AOFRW之前对应的BASE和INCR AOF都将变为HISTORY， HISTORY类型的AOF会被Redis自动删除

为了管理这些AOF文件，我们引入一个manifest(清单)文件来跟踪、管理这些AOF。同时为了便于AOF备份和拷贝， 我们将所有的AOF文件和manifest文件放入一个单独的文件目录中，目录名由appenddirname配置

<br/>

- 恢复的话， 如果都是正常的，那么就是重启redis server时自动读取AOF文件，进行恢复， 但是如果最后一个命令时  flushdb + shutdown服务器， 那么就会在AOF文件中， 记录flushdb， 这时是清空了内存数据的了， 如果这时重新启动服务器， 那么就是是空的了， 因为在AOF文件中由flushdb命令，但是先进入  appendonly.aof.1.incr.aof 然后把 最后一条 flushdb命令给手动删除， 然后重新启动服务器， 这时又能恢复数据
- 如果在 appendonly.aof.1.incr.aof 中存在不符合这个文件的语法的语句，那么重启redis， 就会发现， 启动都启动不了了，
- ![image-20230318170901536](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318170901536.png)
-  这时想要恢复数据， 就要执行，    redis-check-aof --fix 文件名，  这样就能恢复，其实就是检查这个文件，又不合法的就删掉

> 优势：   能更好报数据不丢失、性能高、可做紧急恢复
>
> 劣势:     相同数据的数据而言AOF文件要远大于RDB文件、恢复速度慢于RDB。  AOF运行效率要慢于RDB，每秒同步策略较好，不同步效率和RDB相同。

AOF重写机制

启动AOF文件的内容压缩， 只保留可以恢复数据的最小指令集

最小指令集：   就是  比如 进行多次 set， 而且还是同一个key， 那么就保留最后一个set key value，  因为最后都是要到这个状态的， 那么我就直接保存最后一个状态， 那么就能减少很多空间了， 这样的所有集合就是最小指令集

存在手动触发和自动触发

默认的配置， 也就是自动触发

![image-20230318173230125](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230318173230125.png)

自动触发：   满足配置文件中的选项后， Redis会记录上次重写时的AOF大小，   默认的配置是当AOF文件大小是上次rewrite后的大小的一倍且文件大小大于64M时，就会触发重写机制

手动触发：   客户端向服务器发送 bgrewriteaof命令

重写机制总的来说：  就是AOF文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对， 然后用最小的命令代替之前记录这个键值对的多条命令，生成一个新的文件然后去替换原来的AOF文件

#### Redis事务

可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有的命令都会序列化，**按顺序地串行执行而不会被其他命令插入，不许加塞**

redis事务，维护的是一个队列， 如果开启的事务的话，那么每执行一条命令，就先加入队列中， 然后执行的时候，再一一执行。

一队列中，一次性、顺序性、排他性的执行一系列命令

常用命令

| 命令                | 描述                                                         |
| ------------------- | ------------------------------------------------------------ |
| MULTI               | 标记一个事务块的开始                                         |
| EXEC                | 执行所有事务块内的命令                                       |
| DISCARD             | 取消事务，放弃执行事务块内的所有命令                         |
| UNWATCH             | 取消watch命令对所有key的监视                                 |
| WATCH key [key ...] | 监视一个或多个key， 如果再事务执行之前这些key，被其他命令所改动，那么事务将被打断 |

一般事务有五种可能的状态

- 正常执行
  - multi
  - set key1 value1
  - get key1
  - set key2 value2
  - exec
  - 就是这中间并没有发生任何的错误，从开启事务 multi 开始， 然后到 exec结束， 没有任何的错误发生，也没有取消事务， 这就表示正常执行
- 放弃事务
  - set k1 1
  - multi
  - set k2 v2 
  - set k3 v3
  - incr k1
  - discard 
  - 这里就是在加入了一些到事务的队列中， 最后取消了 事务， 那么这就是表示放弃该事务，然后上面的所有命令一个都不会执行， 本来 k1的值为1， 然后执行incr 自增了1， 本应该是 2, 但是最后还是1, 就表示 上面的所有的命令不会执行
- 全体连坐
  - multi
  - set k1 v1
  - set k2 v2
  - **set k3**
  - exec
  - 在这时就是全体连坐， 就是全部都不会执行， 因为这时有一个命令是错误的，**set k3**   这个在执行的时候就会报错， 如果你还继续 执行事务的话，那么就会 全部失效， 不会执行

- 冤头债主

  - 这个是在运行的时候才知道那个 又错误， 其实就是  哪个错了就哪个不执行， 那些没有错的还是照样执行。

- watch监控

  - 悲观锁： 字面意思，很悲观， 每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到他拿到锁
  - 乐观锁：  字面意思，很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据。

  在redis中使用的是 **乐观锁** ， 因为 redis注重性能， 所以使用的是乐观锁

  **如果要监控某个键的话， 就是 *先监控后开启事务multi*， 保证两个key变动在同一个事务内**

  因为wacth命令是一种乐观锁的实现，Redis在修改的时候会检测数据是否被更改， 如果更改了，则执行失败，  最后  exec 执行事务的事务，就会报一个  nil  。

  如果执行  unwacth 命令的话， 那么就是 取消所有的 监控事件，  如果有变更 就让他变更， 就是你做你的 他做他的。

- 一旦执行了  exec 之前加的监控锁就都会被取消掉了，当客户端连接丢失的时候， 所有东西也都会被取消监控  

总结：   以 **MULTI** 开始一个事务，  之后  就是  将多个命令入队到事务中， 接到这些命令并不会立即执行，而是放到等待执行的事务队列里面，  最后  由 EXEC命令触发事务。

#### Redis管道

redis管道，主要就是 **解决频繁命令往返造成的性能瓶颈**。

Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。一个请求会遵循以下步骤：

1.  客户端向服务端发送命令分四步(发送命令→命令排队→命令执行→返回结果)，并监听Socket返回，通常以阻塞模式等待服务端响应。

2. 服务端处理命令，并将结果返回给客户端。

**上述两步称为：Round Trip Time(简称RTT, 数据包往返于两端的时间)**。

如果同时需要执行大量的命令，那么就要等待上一条命令应答后再执行，这中间不仅仅多了RTT（Round Time Trip），而且还频繁调用系统IO，发送网络请求，同时需要redis调用多次read()和write()系统方法，系统方法会将数据从用户态转移到内核态，这样就会对进程上下文有比较大的影响了，性能不太好

所以， redis管道，就能相对的解决这个问题， 但也不是说redis管道就完美， 也是有一定缺陷的。

redis管道(Pipeline)： Pipeline是为了解决RTT往返时， 仅仅是将命令打包一次性发送，对整个Redis的执行不造成其他任何影响。

总的来说，就是 批量处理命令的变种优化措施，  有点类似原生的 mget， mset命令。但 mset， 只能批处理一种类型的， 如果设置的是String类型的， 就不能设置 Hash类型， 但是Redis管道就能设置多种类型的

Pipeline和原生的对比

| Pipeline                           | 原生批量命令                         |
| ---------------------------------- | ------------------------------------ |
| pipeline是非原子性                 | 原生批量命令是原子性的（mset, mget） |
| pipeline支持批量执行不同命令       | 原生批量命令一次只能执行一种命令     |
| pipeline需要服务端和客户端共同完成 | 原生批量命令是服务端实现的           |

一般都是在linux中先创建一个txt文件， 然后在这个文件中 写了你想要的命令， 可以写很多不同的命令， 如果要执行的话，  那就执行   ```cat xxx.txt | redis-cli -h xxx -a xxx --pipe``` 意思就是 把前面的显示的内容交给 redis管道， 然后再交给 redis服务，最后返回。

Pipeline和事务的对比

| Pipeline                                 | 事务                                                         |
| ---------------------------------------- | ------------------------------------------------------------ |
| 管道不具有原子性                         | 事务具有原子性                                               |
| 管道一次性将多条命令发送到服务器         | 事务是一条一条发的， 只不过先放到事务队列中，等待接收exec命令，接收到了就是从队列中 一条一条执行 |
| 管道中命令执行时，不会阻塞其他命令的执行 | 执行事务是会阻塞其他命令的执行                               |

pipeline缓冲的指令只是会依次执行，不保证原子性， 如果执行中指令发生异常，将会继续执行后面的命令。

使用pipeline组装的命令个数也不能太多了， 不然数据量过大客户端阻塞的事件可能过久， 同服务端此时也被迫恢复一个队列答复，占用很多内存。

#### Redis复制

主从复制， 也就是分为主机(master)和从机(slave)， 主机(master)主要以写为主，从机(Slave)以读为主，总的来说，**主机是能正常的读写**，任何命令都能执行， 但是**从机(Slave) 就只能读， 不能写**， 当master数据变化的时候，自动将新的数据异步同步到其他的slave数据库上。

1. 读写分离，能使提升主机的性能。
2. 如果发生了一些灾难， 主机上的数据被破环了，那么这时就容易恢复。
3. 其实从机就相当于是不断的备份主机上的数据。
4. 水平扩容支撑高并发

- 都是在从机的配置文件中配置相关的信息， 主机是不用配置什么信息的(**配从不配主**)。

- master如果配置了requirepass 参数， 那么就需要密码登录，  所以slave就要配置masterauth来设置校验密码，否则的话master就会拒绝slave的访问。



| info replication            | 可以查看复制节点的主从关系和配置信息                         |
| --------------------------- | ------------------------------------------------------------ |
| replication 主库IP 主库端口 | 一般是写入进redis.conf配置文件内的， 设置当前的数据库的主人是谁 |
| slaveof 主库IP 主库端口     | 每次于master断开之后，都需要重新连接，除非配置进了redis.conf文件，在运行期间修改slave节点的信息，如果该数据库已经是某个主数据库的从数据库，那么会停止和原主数据库的同步关系转而和新的主数据库同步， 也就是 **重新拜码头** |
| slaveof no one              | 使当前数据停止于其他数据库的同步，转成主数据库，自立为王     |

一般来讲，我们自己模拟的时候只要三台虚拟机就行了， 一主二从，  都是要装上redis的

1. 都是遵循配从不配主，  但是一般要主机上配置，相应的密码， 也就是在```requirepass```中 配置密码， 总的来说其实是配置
   - 开启  daemonize yes，   这个表示  在后台运行
   - 注释掉 bind 127.0.0.1 表示只能本机相连  可以写成  bind 0.0.0.0  表示任何IP地址都能相连
   - protected-mode no    默认是no   表示 安全保护模式
   - 指定  port  端口
   - 指定当前工作目录  dir
   - pid文件名字  pidfile
   - log文件名字   logfile
   - requirepass  设置当前所在的redis的密码
   - dump.rdb   名字，  这个就是  RDB持久化时生成的文件
   - aof，  appendonly，   这个可开启， 也可以不开启
2. 然后在从机中配置， 主机是不用配置这个的， 这个就是配从不配主
   - replicaof  主机ip 主机端口
   - masterauth 主机密码
3.   最后就是要通过防火墙打开相应的端口， 不然还是连接不上  ```firewall-cmd --add-port=xxxx/tcp```,打开一个xxxx端口， 这样才能连接到

> 一旦连上了的话，   那么就是 一台主机，  两台从机
>
> 1. 从机是不能执行写命令的， 删除也是不能的，  就是单纯的执行读， 就只能读
> 2. 如果主机先写了一些数据了， 之后从机才连上， 从机还是能把之前写的数据，备份起来， 也就是先把之前保存，然后再继续同步更新
> 3. 主机shutdown了，  从机是不会上位的，还是原地待命，等主机王者归来
> 4. 主机shutdown了， 重启后主从关系还是依然在的
> 5. 从机shutdown了，  但是主机还是一样写数据， 之后从机重启之后，还是不会之前没有保存到的数据， 备份一份，  先跟上大部队， 然后再同步
> 6. 如果去掉从机配置项的配置， 那么又会重新变成master
> 7. 如果使用命令的话， 那么也就是这一次连接是主从关系， shutdown之后就不是了
> 8. 从机还能 当下一个从机master， 减少主机写的压力， 但是从机依然是从机， 还是不能执行写的命令

复制原理和工作流程

1. slave启动， 同步初请
   1. slave启动成功连接到master后会发送一个sync命令
   2. slave首次全新连接master，一次完全同步（全量复制）将被自动执行，slave自身原有数据会被master数据覆盖清除
2. 首次连接， 全量复制
   1. master节点收到sync命令后会开始再后台保存快照（RDB持久化，主从复制会触发RDB）同时搜集所有接收到的用于修改数据集命令缓存起来，master节点执行RDB持久化完后，masterjiangrdb快照文件和所有缓存的命令发送到所有slave，以完成一次完全同步
   2. 而slave服务在接收到数据库文件数据后， 将其存盘并加载到内存中，从而完成复制初始化
3. 心跳持续，保持通信
   1. repl-ping-replica-period 10     master发出PING包的周期默认是10秒
4. 进入平稳， 增量复制
   1. master继续将新的所有收集到的修改命令自动依次传给slave，完成同步
5. 从机下线，重连续传
   1. master会检查backlog里面的offset，master和slave都会保存一个复制的offset还有一个masterID，offset是保存在backlog中的， ``` master只会把已经复制的offset后面的数据复制给slave```，类似断点续传

主从复制的缺点也是很明显的，  

- 复制延时，信号衰减
- 如果master挂了，  这时就不能在执行写的操作了， 只能默默等主机回来， 或者人工干预， 这样就很不好了

#### Redis哨兵(sentinel)

##### 哨兵是什么

哨兵其实就是一个吹哨人，监控后台的master主机是否出现故障，如果出现了故障就**根据投票数**自动将某一个从库转换为新的主机， 继续对外服务。

##### 能干什么

- 主从监控，监控主从redis库运行是否正常

- 消息通知， 哨兵可以将故障转移的结果发送给客户端
- 故障转移， 如果master异常，则会进行主从切换，将其中一个Slave作为新的master
- 配置中心， 客户端通过连接哨兵来获得当前Redis服务得主节点地址

一般来说配置三个及以上的奇数个哨兵就行了， 其实在配置哨兵的同时， 要有主从复制， 因为哨兵就是在主从复制的基础上添加的， 主要是完善主从复制的不足，使数据的丢失更少。 但是还是不能实现零数据丢失。后面就会引出集群

在配置的哨兵的配置信息时， 一般只要配置

- bind    服务监听地址， 用户于客户端连接，默认是本机的地址
- daemonize  是否开启后台的daemonize， 其实就是是后台运行
- protected-mode   是否开启安全保护机制
- port   端口号，  默认的端口号是，  26379
- logfile      日志文件路径
- pidfile    pid文件路径
- dir   工作目录
- **sentinel monitor <master-name> <ip> <redis-port> <quorum>**   设置要监控master服务器的地址，端口，最主要的  quorum表示最少有几个哨兵认为客观下线， 同意故障迁移的法定票数
- **sentinel auth-pass <master-name> <password>**     如果主机设置了密码的话，  那么在配置哨兵的时候就一定也要填写主机的密码， 不然是监控不到主机的
- 最后两个是最主要的， 只有配置了这两个，才算真正意义上配置哨兵的信息

>bind 0.0.0.0
>
>daemonize yes
>
>protected-mode no
>
>port 26379
>
>logfile "/myredis/sentinel26379.log"
>
>pidfile /var/run/redis-sentinel26379.pid
>
>dir /myredis
>
>sentinel monitor mymaster 192.168.111.169 6379 2
>
>sentinel auth-pass mymaster 111111
>
> 这里就是一个比较完整的哨兵的配置信息， 里面的 地址什么的  就是填你自己电脑的当前的地址
>
>其实这里的主机和从机上的密码 配置成一样的最好， 因为一旦原主机下线， 之后再登上了之后，那么主机就会变成slave了，这时就要连接之前的slave， 所以把密码设置成一样的更好

如果要配置几个哨兵，那么就配置几份这样配置文件， 如果要启动哨兵

- redis-sentinel sentinel26379.conf --sentinle     这样就启动了一个哨兵监控， 如果还要再启动其他的，那么就只要改变，  配置文件的名字就行了。

如果要查看哨兵的情况， 那么就要去查看哨兵的日志文件了， 一开始没有出现事故的时候，那么就都是正常的，主机执行正常的  读和写，  从机就是备份， 只能读。

但是一旦主机宕机了， 这时我们就得考虑几个问题了

- 两台从机上的数据是否正常还在， 是否还能读取
  -  答案是显然的，  数据当然还在， 还是依然能读取的
- 是否会从剩下的从机中选出新的master
  - 答案也是显然的，  依然能选出新的master，作为新的主机
- 之前宕机了的主机重启回来之后， 还会重新变成主机吗
  - 这个是不会的， 现在已经变成里 slave了

上面所有问题的答案， 其实都要在他们相应的日志文件中能找出来

>--------
>
>fwae 
>
>------
>
>fwea 

其实在原先的主机宕机的那么一会，  从机的数据找不到， 其实并不是数据的丢失， 而是出现了，broken pipe

> broken pipe的意思是 对端的管道已经断开，往往发生在远端把这个 读写管道关闭了， 你无法在管道里写数据， 第一次， 你会收到一个远端发送的RST信号， 如果你继续往管道写数据， 操作系统就会给你发送SIGPIPE的信号， 并且signal(SIGPIPE  SIG IGN) 忽略这个信号， 这样的话，程序不会退出， 但是写 会返回-1， 并且将 errno置为Broken pipe。  broken pipe只会出现在往对端已经的管道里写数据的情况下。

从原来的slave中选出一个 master， 也就是升级为master， 以前的 master， 就会将为slave

在生产中， 一般是不会出现所有的哨兵都挂掉的情况， 主要是， 每个哨兵不放在同一台服务器上， 而是放置在不同的设备上

##### 哨兵运行流程和选举原理

当一个主从配置中的master失效之后， sentinel可以选举出一个新的master用于自动接替原master的工作。 主从配置中的其他redis服务器自动指向新的master同步数据。一般建议sentinel采取奇数台，防止某一个sentinel无法连接到master导致误切换。

##### SDown主观下线

所谓主观下线（Subjectively Down， 简称 SDOWN）指的是单个Sentinel实例对服务器做出的下线判断，即单个sentinel认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。主观下线就是说如果服务器在[sentinel down-after-milliseconds]给定的毫秒数之内没有回应PING命令或者返回一个错误消息， 那么这个Sentinel会主观的(单方面的)认为这个master不可以用了

sentinel down-after-milliseconds <masterName> <timeout>

 表示master被当前sentinel实例认定为失效的间隔时间，这个配置其实就是进行主观下线的一个依据

master在多长时间内一直没有给Sentine返回有效信息，则认定该master主观下线。也就是说如果多久没联系上redis-servevr，认为这个redis-server进入到失效（SDOWN）状态。

##### ODown客观下线

masterName是对某个master+slave组合的一个区分标识(一套sentinel可以监听多组master+slave这样的组合)

**quorum这个参数是进行客观下线的一个依据**，法定人数/法定票数

意思是至少有quorum个sentinel认为这个master有故障才会对这个master进行下线以及故障转移。因为有的时候，某个sentinel节点可能因为自身网络原因导致无法连接master，而此时master并没有出现故障，所以这就需要多个sentinel都一致认为该master有问题，才可以进行下一步操作，这就保证了公平性和高可用。

其实在哨兵中也要先进行一波 选举， 在哨兵中选举出， 领导者(兵王)，  然后再有这个领导者， 再slave中选举出新的master，  选举出兵王， 是利用  Raft算法， 这个算法的基本思想就是 先到先得

#### 哨兵使用建议

- 哨兵节点数量应为多个， 哨兵本身应该集群，保证高可用
- 哨兵节点的数量应该是奇数
- 各个哨兵节点的配置应一致
- 如果哨兵节点部署再Docker等容器里面，尤其要注意端口的正确的映射
- 烧饼集群+主从复制，并不能保证数据零丢失，  所以要使用集群了

#### Redis集群

##### 那集群是什么呢

Redis集群是一个提供在多个Redis节点间共享数据的程序集， Redis集群可以支持多个Master

##### 能干什么

Redis集群支持多个Master，每个Master又可以挂载多个Slave，

	- 实现读写分离， 
	- 支持数据的高可用
	-  支持海量数据的读写存储曹操作

由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持，无需再去使用哨兵功能

客户端与Redis的节点连接，不再需要连接集群中所有的节点，只需要任意连接集群中的一个可用节点即可

槽位slot负值分配到各个物理服务节点，由对应的集群来负责维护节点， 插槽和数据之间的关系

##### 集群算法-分片-槽位slot

Redis集群的数据分片

Redis集群没有使用一致性hash， 而是引入了 哈希槽的概念

redis集群有 16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置那个槽，集群的每个节点负责一部分hash槽

举个例子， 比如当前集群中有三个节点， 那么

![image-20230402210031120](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402210031120.png)

redis集群的分片

| 分片是什么            | 使用Redis集群时我们会将存储的数据分散到多台redis机器上，这称为分片。简言之，集群中的每个Redis实例都被认为是整个数据的一个分片。 |
| --------------------- | ------------------------------------------------------------ |
| 如何找到给定key的分片 | 为了找到给定key的分片，我们对key进行CRC16(key)算法处理并通过对总分片数量取模。然后，使用确定性哈希函数，这意味着给定的key将多次始终映射到同一个分片，我们可以推断将来读取特定key的位置。 |

![image-20230402210238490](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402210238490.png)

上面这个两个的优势：

**最大优势，方便扩缩容和数据分派查找**

这种结构很容易添加或则删除节点， 比如如果我想新添加个节点D, 我需要从节点A,B,C中得部分槽到D上， 如果我想移除节点A， 那么需要将A中的槽移到B和C节点上，然后将没有任何槽A节点从集群中移除即可， 由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状体

![image-20230402210753814](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402210753814.png)

slot槽位映射， 一般业界有三种解决方案

- 哈希区域分区

  - ![image-20230402211244098](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402211244098.png)

  - 2亿条记录就是2亿个k,v，我们单机不行必须要分布式多机，假设有3台机器构成一个集群，用户每次读写操作都是根据公式：

    hash(key) % N个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。

  - 优点：

     简单粗暴，直接有效，只需要预估好数据规划好节点，例如3台、8台、10台，就能保证一段时间的数据支撑。使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用。

  - 缺点：  原来规划好的节点，进行扩容或者缩容就比较麻烦了额，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3会变成Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。某个redis机器宕机了，由于台数数量变化，会导致hash取余全部数据重新洗牌。

- 一致性哈希算法分区

  - 一致性Hash算法背景

    　　一致性哈希算法在1997年由麻省理工学院中提出的，设计目标是为了解决

    分布式缓存数据变动和映射问题，某个机器宕机了，分母数量改变了，自然取余数不OK了。

  - 提出一致性Hash解决方案。 目的是当服务器个数发生变动时，尽量减少影响客户端到服务器的映射关系

  - 三大步骤

    - 算法构建一致性哈希环

      - 一致性哈希环

          一致性哈希算法必然有个hash函数并按照算法产生hash值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个hash空间[0,2^32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连(0 = 2^32),这样让它逻辑上形成了一个环形空间。

          它也是按照使用取模的方法，前面笔记介绍的节点取模法是对节点（服务器）的数量进行取模。而一致性Hash算法是对2^32取模，简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下图：整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。

        ![image-20230402211639227](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402211639227.png)

    - redis服务器IP节点映射

      - 节点映射

          将集群中各个IP节点映射到环上的某一个位置。

          将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如4个节点NodeA、B、C、D，经过IP地址的哈希函数计算(hash(ip))，使用IP地址哈希后在环空间的位置如下： 

        ![image-20230402211709921](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402211709921.png)

    - key落到服务器的落键规则

      - 当我们需要存储一个kv键值对时，首先计算key的hash值，hash(key)，将这个key使用相同的函数Hash计算出哈希值并确定此数据在环上的位置，**从此位置沿环顺时针“行走”**，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。

        如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。

        ![image-20230402211737230](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402211737230.png)

  - 优点

    - 一致性哈希算法的容错性

      - **容错性**

        假设Node C宕机，可以看到此时对象A、B、D不会受到影响。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。简单说，就是C挂了，受到影响的只是B、C之间的数据且这些数据会转移到D进行存储。

        ![image-20230402212158134](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402212158134.png)

    - 一致性哈希算法的扩展性

      -  扩展性

        数据量增加了，需要增加一台节点NodeX，X的位置在A和B之间，那收到影响的也就是A到X之间的数据，重新把A到X的数据录入到X上即可，

        不会导致hash取余全部数据重新洗牌。

        ![image-20230402212233787](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402212233787.png)

  - 缺点

    - 一致性哈希算法的数据倾斜问题

      - Hash环的数据倾斜问题

        一致性Hash算法在服务**节点太少时**，容易因为节点分布不均匀而造成**数据倾斜**（被缓存的对象大部分集中缓存在某一台服务器上）问题，

        例如系统中只有两台服务器：

        ![image-20230402212347383](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402212347383.png)

  - 总结

    - 为了在节点数目发生改变时尽可能少的迁移数据

       

      将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到临近的存储节点存放。

      而当有节点加入或退出时仅影响该节点在Hash环上顺时针相邻的后续节点。 

      优点

      加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。

      缺点 

      数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。

- 哈希分区

  - 为什么出现

    - 一致性哈希算法的数据倾斜问题

      - 哈希槽实质就是一个数组，数组[0,2^14 -1]形成hash slot空间。

    - 能干什么

      - 解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽（slot），用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。

      - ![image-20230402212729422](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402212729422.png)

      - 槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。哈希解决的是映射问题，使用key的哈希值来计算所在的槽，便于数据分配

        3 多少个hash槽

        一个集群只能有16384个槽，编号0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。

        集群会记录节点和槽的对应关系，解决了节点和槽的关系后，接下来就需要对key求哈希值，然后对16384取模，余数是几key就落入对应的槽里。HASH_SLOT = CRC16(key) mod 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。

  - 哈希槽计算

    - 槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。哈希解决的是映射问题，使用key的哈希值来计算所在的槽，便于数据分配

      3 多少个hash槽

      一个集群只能有16384个槽，编号0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。

      集群会记录节点和槽的对应关系，解决了节点和槽的关系后，接下来就需要对key求哈希值，然后对16384取模，余数是几key就落入对应的槽里。HASH_SLOT = CRC16(key) mod 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。

      ![image-20230402212831592](C:\Users\天若有情天亦老\AppData\Roaming\Typora\typora-user-images\image-20230402212831592.png)

  - 
